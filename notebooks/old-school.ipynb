{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         processed_words   ups  ups_normed  \\\n",
       "0      [sometimesth, face, go, work, get, shoot, stro...   1.0    0.000001   \n",
       "1      [time, come, barter, pandem, day, roll, toilet...  27.0    0.000036   \n",
       "2      [gang, derin, mlke, wey, stealin, steve, panel...   1.0    0.000001   \n",
       "3      [desper, time, desper, hoard, toilet, paper, b...   1.0    0.000001   \n",
       "4      [desper, time, desper, hoard, toilet, paper, b...   1.0    0.000001   \n",
       "...                                                  ...   ...         ...   \n",
       "69937  [stop, act, like, onegover, work, home, clown,...   1.0    0.000021   \n",
       "69938    [go, right, choos, fighter, im, go, top, right]   1.0    0.000021   \n",
       "69939  [pound, multi, million, dollar, compani, plant...   1.0    0.000021   \n",
       "69940                 [second, virus, kill, second, one]   1.0    0.000021   \n",
       "69941  [onegovern, work, home, grave, digger, first, ...   1.0    0.000021   \n",
       "\n",
       "       TextLength  Sentiment  word_count  dank_level  \n",
       "0           118.0       0.58         8.0         0.0  \n",
       "1            93.0       0.29         8.0         0.0  \n",
       "2           114.0       0.43         8.0         0.0  \n",
       "3            97.0       0.18         8.0         0.0  \n",
       "4            97.0       0.18         8.0         0.0  \n",
       "...           ...        ...         ...         ...  \n",
       "69937        55.0       0.43         7.0         0.0  \n",
       "69938        62.0       0.49         4.0         0.0  \n",
       "69939        98.0       0.59         8.0         0.0  \n",
       "69940        56.0       0.42         3.0         0.0  \n",
       "69941        54.0       0.42         5.0         0.0  \n",
       "\n",
       "[69942 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_words</th>\n      <th>ups</th>\n      <th>ups_normed</th>\n      <th>TextLength</th>\n      <th>Sentiment</th>\n      <th>word_count</th>\n      <th>dank_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[sometimesth, face, go, work, get, shoot, stro...</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>118.0</td>\n      <td>0.58</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[time, come, barter, pandem, day, roll, toilet...</td>\n      <td>27.0</td>\n      <td>0.000036</td>\n      <td>93.0</td>\n      <td>0.29</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[gang, derin, mlke, wey, stealin, steve, panel...</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>114.0</td>\n      <td>0.43</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[desper, time, desper, hoard, toilet, paper, b...</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[desper, time, desper, hoard, toilet, paper, b...</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69937</th>\n      <td>[stop, act, like, onegover, work, home, clown,...</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>55.0</td>\n      <td>0.43</td>\n      <td>7.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69938</th>\n      <td>[go, right, choos, fighter, im, go, top, right]</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>62.0</td>\n      <td>0.49</td>\n      <td>4.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69939</th>\n      <td>[pound, multi, million, dollar, compani, plant...</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>98.0</td>\n      <td>0.59</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69940</th>\n      <td>[second, virus, kill, second, one]</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>56.0</td>\n      <td>0.42</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69941</th>\n      <td>[onegovern, work, home, grave, digger, first, ...</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>54.0</td>\n      <td>0.42</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>69942 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/nlp_ready.csv\", converters={0:ast.literal_eval})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-3-f4722811cd9c>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X['processed_words'] = X['processed_words'].apply(lambda x: \" \".join(x) )\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 'dank_level']\n",
    "X['processed_words'] = X['processed_words'].apply(lambda x: \" \".join(x) )\n",
    "y = data[\"dank_level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 43.0 GiB for an array with shape (69942, 82545) and data type int64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-276072bda6bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed_words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtext_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 43.0 GiB for an array with shape (69942, 82545) and data type int64"
     ]
    }
   ],
   "source": [
    "text_train = vectorizer.fit_transform(X['processed_words'])\n",
    "text_train = pd.DataFrame(text_train.toarray(), columns=vectorizer.get_feature_names())\n",
    "text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}