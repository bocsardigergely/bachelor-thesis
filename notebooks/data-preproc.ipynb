{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "source": [
    "# Loading data from the linked repo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (3,4,5,8,9,10,11,14,16,18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"../data/final_dank.csv\")\n"
   ]
  },
  {
   "source": [
    "# Selecting relevant attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['awards' 'processed_words' 'created_utc' 'downs' 'id' 'is_nsfw' 'media'\n 'subreddit' 'subscribers' 'thumbnail.height' 'thumbnail.thumbnail'\n 'thumbnail.width' 'title' 'ups' 'url' 'datetime_temp' 'time_of_day'\n 'ups_normed' 'dank_level' 'TextLength' 'Sentiment' 'word_count']\n-----------------\n['processed_words' 'title' 'ups' 'ups_normed' 'dank_level' 'TextLength'\n 'Sentiment' 'word_count']\n"
     ]
    }
   ],
   "source": [
    "l = list(raw_data.columns.values)\n",
    "\n",
    "l1 = l[4:26]\n",
    "data = raw_data[l1]\n",
    "print(data.columns.values)\n",
    "data1 = data.drop(columns=['is_nsfw','media','thumbnail.height', 'thumbnail.thumbnail', 'thumbnail.width','time_of_day', 'datetime_temp', 'id', 'subreddit', 'url', 'created_utc', 'subscribers', 'downs', 'awards'])\n",
    "print(\"-----------------\")\n",
    "print(data1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data1['dank_level'].unique()\n",
    "# ezzel ez lesz a célváltozónk, bináris osztályozás esetén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         processed_words  \\\n",
       "0      ['sometimesth', 'face', 'go', 'work', 'get', '...   \n",
       "1      ['time', 'come', 'barter', 'pandem', 'day', 'r...   \n",
       "2      ['gang', 'derin', 'mlke', 'wey', 'stealin', 's...   \n",
       "3      ['desper', 'time', 'desper', 'hoard', 'toilet'...   \n",
       "4      ['desper', 'time', 'desper', 'hoard', 'toilet'...   \n",
       "...                                                  ...   \n",
       "69937  ['stop', 'act', 'like', 'onegover', 'work', 'h...   \n",
       "69938                ['go', 'right', 'choos', 'fighter']   \n",
       "69939  ['pound', 'multi', 'million', 'dollar', 'compa...   \n",
       "69940                        ['second', 'virus', 'kill']   \n",
       "69941   ['onegovern', 'work', 'home', 'grave', 'digger']   \n",
       "\n",
       "                                                   title processed_title  \\\n",
       "0                          It just be that way sometimes           Empty   \n",
       "1      The time has come for the barter of pandemic d...           Empty   \n",
       "2                                   Day 10 of quarantine           Empty   \n",
       "3                   Desperate times, Desperate solutions           Empty   \n",
       "4                   Desperate times, Desperate solutions           Empty   \n",
       "...                                                  ...             ...   \n",
       "69937                               stop acting like one           Empty   \n",
       "69938        im going with the top right what about you?           Empty   \n",
       "69939                                         SAM POUND!           Empty   \n",
       "69940                                      My Second one           Empty   \n",
       "69941                                       My first one           Empty   \n",
       "\n",
       "        ups  ups_normed  dank_level  TextLength  Sentiment  word_count  \n",
       "0       1.0    0.000001         0.0       118.0       0.58         8.0  \n",
       "1      27.0    0.000036         0.0        93.0       0.29         8.0  \n",
       "2       1.0    0.000001         0.0       114.0       0.43         8.0  \n",
       "3       1.0    0.000001         0.0        97.0       0.18         8.0  \n",
       "4       1.0    0.000001         0.0        97.0       0.18         8.0  \n",
       "...     ...         ...         ...         ...        ...         ...  \n",
       "69937   1.0    0.000021         0.0        55.0       0.43         7.0  \n",
       "69938   1.0    0.000021         0.0        62.0       0.49         4.0  \n",
       "69939   1.0    0.000021         0.0        98.0       0.59         8.0  \n",
       "69940   1.0    0.000021         0.0        56.0       0.42         3.0  \n",
       "69941   1.0    0.000021         0.0        54.0       0.42         5.0  \n",
       "\n",
       "[69942 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_words</th>\n      <th>title</th>\n      <th>processed_title</th>\n      <th>ups</th>\n      <th>ups_normed</th>\n      <th>dank_level</th>\n      <th>TextLength</th>\n      <th>Sentiment</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['sometimesth', 'face', 'go', 'work', 'get', '...</td>\n      <td>It just be that way sometimes</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>118.0</td>\n      <td>0.58</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['time', 'come', 'barter', 'pandem', 'day', 'r...</td>\n      <td>The time has come for the barter of pandemic d...</td>\n      <td>Empty</td>\n      <td>27.0</td>\n      <td>0.000036</td>\n      <td>0.0</td>\n      <td>93.0</td>\n      <td>0.29</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['gang', 'derin', 'mlke', 'wey', 'stealin', 's...</td>\n      <td>Day 10 of quarantine</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>114.0</td>\n      <td>0.43</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['desper', 'time', 'desper', 'hoard', 'toilet'...</td>\n      <td>Desperate times, Desperate solutions</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['desper', 'time', 'desper', 'hoard', 'toilet'...</td>\n      <td>Desperate times, Desperate solutions</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69937</th>\n      <td>['stop', 'act', 'like', 'onegover', 'work', 'h...</td>\n      <td>stop acting like one</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>0.43</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>69938</th>\n      <td>['go', 'right', 'choos', 'fighter']</td>\n      <td>im going with the top right what about you?</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>62.0</td>\n      <td>0.49</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>69939</th>\n      <td>['pound', 'multi', 'million', 'dollar', 'compa...</td>\n      <td>SAM POUND!</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>98.0</td>\n      <td>0.59</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>69940</th>\n      <td>['second', 'virus', 'kill']</td>\n      <td>My Second one</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>56.0</td>\n      <td>0.42</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>69941</th>\n      <td>['onegovern', 'work', 'home', 'grave', 'digger']</td>\n      <td>My first one</td>\n      <td>Empty</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>54.0</td>\n      <td>0.42</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>69942 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# filtering where label is NA\n",
    "data_useful = data1.loc[data1['dank_level'].notna()]\n",
    "data_useful.insert(2, \"processed_title\", \"Empty\")\n",
    "data_useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The time has come for the barter of pandemic days.\nThe time has come for the barter of pandemic days \nthe time has come for the barter of pandemic days \n['time', 'come', 'barter', 'pandemic', 'days']\n"
     ]
    }
   ],
   "source": [
    "# testing some nltk\n",
    "tester = data_useful['title'][1]\n",
    "print(tester)\n",
    "# remove punctuation\n",
    "punctless = re.sub('[^a-zA-Z]', ' ', tester)\n",
    "print(punctless)\n",
    "# lowercase\n",
    "lowercase = punctless.lower()\n",
    "print(lowercase)\n",
    "# stopword removal\n",
    "words_list = lowercase.split()\n",
    "words_list =  [word for word in words_list if not word in set(stopwords.words('english'))]\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['time', 'come', 'barter', 'pandem', 'day']\n"
     ]
    }
   ],
   "source": [
    "# first try at stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "word_stem = []\n",
    "for word in words_list:\n",
    "    word_stem.append(stemmer.stem(word))\n",
    "print(word_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the processed words are not lemmatized as far as i know, will need to look into that\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    punctless = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    lowercase = punctless.lower()\n",
    "    words_list = lowercase.split()\n",
    "    words_list =  [word for word in words_list if not word in set(stopwords.words('english'))]\n",
    "    for word in words_list:\n",
    "        result.append(lemmatize_stemming(word))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['time', 'come', 'barter', 'pandem', 'day']\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(data_useful['title'][1]))"
   ]
  },
  {
   "source": [
    "Consistent preproc with the OG repo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-22-feb616b1776f>:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data_useful['processed_title'][ind] = processed_title\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3343: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "for ind in data_useful.index:     \n",
    "    if data_useful['processed_title'][ind] == 'Empty':\n",
    "        words = data_useful['title'][ind]\n",
    "        try:\n",
    "            processed_title = preprocess(words)\n",
    "        except:\n",
    "            processed_words = 'Fail'\n",
    "        data_useful['processed_title'][ind] = processed_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_useful.drop(columns=\"title\")\n",
    "data_final.to_csv(\"../data/nlp_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}