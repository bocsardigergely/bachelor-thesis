{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "source": [
    "# Loading data from the linked repo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (3,4,5,8,9,10,11,14,16,18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"../data/final_dank.csv\")\n"
   ]
  },
  {
   "source": [
    "# Selecting relevant attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['awards' 'processed_words' 'created_utc' 'downs' 'id' 'is_nsfw' 'media'\n 'subreddit' 'subscribers' 'thumbnail.height' 'thumbnail.thumbnail'\n 'thumbnail.width' 'title' 'ups' 'url' 'datetime_temp' 'time_of_day'\n 'ups_normed' 'dank_level' 'TextLength' 'Sentiment' 'word_count']\n-----------------\n['processed_words' 'title' 'ups' 'ups_normed' 'dank_level' 'TextLength'\n 'Sentiment' 'word_count']\n"
     ]
    }
   ],
   "source": [
    "l = list(raw_data.columns.values)\n",
    "\n",
    "l1 = l[4:26]\n",
    "data = raw_data[l1]\n",
    "print(data.columns.values)\n",
    "data1 = data.drop(columns=['is_nsfw','media','thumbnail.height', 'thumbnail.thumbnail', 'thumbnail.width','time_of_day', 'datetime_temp', 'id', 'subreddit', 'url', 'created_utc', 'subscribers', 'downs', 'awards'])\n",
    "print(\"-----------------\")\n",
    "print(data1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data1['dank_level'].unique()\n",
    "# ezzel ez lesz a célváltozónk, bináris osztályozás esetén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         processed_words  \\\n",
       "0      ['sometimesth', 'face', 'go', 'work', 'get', '...   \n",
       "1      ['time', 'come', 'barter', 'pandem', 'day', 'r...   \n",
       "2      ['gang', 'derin', 'mlke', 'wey', 'stealin', 's...   \n",
       "3      ['desper', 'time', 'desper', 'hoard', 'toilet'...   \n",
       "4      ['desper', 'time', 'desper', 'hoard', 'toilet'...   \n",
       "...                                                  ...   \n",
       "69937  ['stop', 'act', 'like', 'onegover', 'work', 'h...   \n",
       "69938                ['go', 'right', 'choos', 'fighter']   \n",
       "69939  ['pound', 'multi', 'million', 'dollar', 'compa...   \n",
       "69940                        ['second', 'virus', 'kill']   \n",
       "69941   ['onegovern', 'work', 'home', 'grave', 'digger']   \n",
       "\n",
       "                                                   title   ups  ups_normed  \\\n",
       "0                          It just be that way sometimes   1.0    0.000001   \n",
       "1      The time has come for the barter of pandemic d...  27.0    0.000036   \n",
       "2                                   Day 10 of quarantine   1.0    0.000001   \n",
       "3                   Desperate times, Desperate solutions   1.0    0.000001   \n",
       "4                   Desperate times, Desperate solutions   1.0    0.000001   \n",
       "...                                                  ...   ...         ...   \n",
       "69937                               stop acting like one   1.0    0.000021   \n",
       "69938        im going with the top right what about you?   1.0    0.000021   \n",
       "69939                                         SAM POUND!   1.0    0.000021   \n",
       "69940                                      My Second one   1.0    0.000021   \n",
       "69941                                       My first one   1.0    0.000021   \n",
       "\n",
       "       dank_level  TextLength  Sentiment  word_count  \n",
       "0             0.0       118.0       0.58         8.0  \n",
       "1             0.0        93.0       0.29         8.0  \n",
       "2             0.0       114.0       0.43         8.0  \n",
       "3             0.0        97.0       0.18         8.0  \n",
       "4             0.0        97.0       0.18         8.0  \n",
       "...           ...         ...        ...         ...  \n",
       "69937         0.0        55.0       0.43         7.0  \n",
       "69938         0.0        62.0       0.49         4.0  \n",
       "69939         0.0        98.0       0.59         8.0  \n",
       "69940         0.0        56.0       0.42         3.0  \n",
       "69941         0.0        54.0       0.42         5.0  \n",
       "\n",
       "[69942 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_words</th>\n      <th>title</th>\n      <th>ups</th>\n      <th>ups_normed</th>\n      <th>dank_level</th>\n      <th>TextLength</th>\n      <th>Sentiment</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['sometimesth', 'face', 'go', 'work', 'get', '...</td>\n      <td>It just be that way sometimes</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>118.0</td>\n      <td>0.58</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['time', 'come', 'barter', 'pandem', 'day', 'r...</td>\n      <td>The time has come for the barter of pandemic d...</td>\n      <td>27.0</td>\n      <td>0.000036</td>\n      <td>0.0</td>\n      <td>93.0</td>\n      <td>0.29</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['gang', 'derin', 'mlke', 'wey', 'stealin', 's...</td>\n      <td>Day 10 of quarantine</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>114.0</td>\n      <td>0.43</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['desper', 'time', 'desper', 'hoard', 'toilet'...</td>\n      <td>Desperate times, Desperate solutions</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['desper', 'time', 'desper', 'hoard', 'toilet'...</td>\n      <td>Desperate times, Desperate solutions</td>\n      <td>1.0</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>97.0</td>\n      <td>0.18</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69937</th>\n      <td>['stop', 'act', 'like', 'onegover', 'work', 'h...</td>\n      <td>stop acting like one</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>0.43</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>69938</th>\n      <td>['go', 'right', 'choos', 'fighter']</td>\n      <td>im going with the top right what about you?</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>62.0</td>\n      <td>0.49</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>69939</th>\n      <td>['pound', 'multi', 'million', 'dollar', 'compa...</td>\n      <td>SAM POUND!</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>98.0</td>\n      <td>0.59</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>69940</th>\n      <td>['second', 'virus', 'kill']</td>\n      <td>My Second one</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>56.0</td>\n      <td>0.42</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>69941</th>\n      <td>['onegovern', 'work', 'home', 'grave', 'digger']</td>\n      <td>My first one</td>\n      <td>1.0</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>54.0</td>\n      <td>0.42</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>69942 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# filtering where label is NA\n",
    "data_useful = data1.loc[data1['dank_level'].notna()]\n",
    "data_useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The time has come for the barter of pandemic days.\nThe time has come for the barter of pandemic days \nthe time has come for the barter of pandemic days \n['time', 'come', 'barter', 'pandemic', 'days']\n"
     ]
    }
   ],
   "source": [
    "# testing some nltk\n",
    "tester = data_useful['title'][1]\n",
    "print(tester)\n",
    "# remove punctuation\n",
    "punctless = re.sub('[^a-zA-Z]', ' ', tester)\n",
    "print(punctless)\n",
    "# lowercase\n",
    "lowercase = punctless.lower()\n",
    "print(lowercase)\n",
    "# stopword removal\n",
    "words_list = lowercase.split()\n",
    "words_list =  [word for word in words_list if not word in set(stopwords.words('english'))]\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['time', 'come', 'barter', 'pandem', 'day']\n"
     ]
    }
   ],
   "source": [
    "# first try at stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "word_stem = []\n",
    "for word in words_list:\n",
    "    word_stem.append(stemmer.stem(word))\n",
    "print(word_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the processed words are not lemmatized as far as i know, will need to look into that\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n"
   ]
  }
 ]
}