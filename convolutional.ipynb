{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = pd.read_csv(\"data/processed/processed_short.csv\")\n",
    "df_medium = pd.read_csv(\"data/processed/processed_medium.csv\")\n",
    "df_long = pd.read_csv(\"data/processed/processed_long.csv\")\n",
    "\n",
    "wv_short = KeyedVectors.load(\"data/df_short.wordvectors\", mmap='r')\n",
    "wv_med = wv = KeyedVectors.load(\"data/df_medium.wordvectors\", mmap='r')\n",
    "wv_long = KeyedVectors.load(\"data/df_long.wordvectors\", mmap='r')"
   ]
  },
  {
   "source": [
    "# Dope megoldás a convnetre a cikkből, aminek a képét is beraktam"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodels = []\n",
    "for kw in (3, 4, 5):    # kernel sizes\n",
    "    submodel = Sequential()\n",
    "    submodel.add(Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False))\n",
    "    submodel.add(Conv1D(FILTERS,    #should be 100 maps\n",
    "                        kw,\n",
    "                        padding='valid',\n",
    "                        activation='relu',\n",
    "                        strides=1)) #elvileg egy maxnorm nem árt még bele\n",
    "    submodel.add(GlobalMaxPooling1D())\n",
    "    submodels.append(submodel)\n",
    "big_model = Sequential()\n",
    "big_model.add(Merge(submodels, mode=\"concat\"))\n",
    "big_model.add(Dense(HIDDEN_DIMS))\n",
    "big_model.add(Dropout(P_DROPOUT))\n",
    "big_model.add(Activation('relu'))\n",
    "big_model.add(Dense(1))\n",
    "big_model.add(Activation('sigmoid'))\n",
    "print('Compiling model')\n",
    "big_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = big_model.fit([x_train, x_train, x_train],\r\n",
    "                     y_train,\r\n",
    "                     batch_size=BATCH_SIZE,\r\n",
    "                     epochs=EPOCHS,\r\n",
    "                     validation_data=([x_val, x_val, x_val], y_val),\r\n",
    "                     callbacks=callbacks)"
   ]
  }
 ]
}