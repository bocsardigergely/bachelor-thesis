{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
      "display_name": "Python 3.8.3 64-bit (conda)"
    },
    "colab": {
      "name": "convolutional.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ApkXQimtmp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vtknUv4mtmr"
      },
      "source": [
        "df_short = pd.read_csv(\"https://raw.githubusercontent.com/bocsardigergely/bachelor-thesis/main/data/processed/processed_short.csv\").sample(frac=1).reset_index(drop=True)\n",
        "df_medium = pd.read_csv(\"https://raw.githubusercontent.com/bocsardigergely/bachelor-thesis/main/data/processed/processed_medium.csv\").sample(frac=1).reset_index(drop=True)\n",
        "df_dank = pd.read_csv(\"https://raw.githubusercontent.com/bocsardigergely/bachelor-thesis/main/data/processed/processed_dank.csv\").sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOy50udmmtmt"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsdthDI-wXBD"
      },
      "source": [
        "df_joint = pd.concat([df_short, df_medium, df_dank])\n",
        "df_joint = df_joint.reset_index(drop=True)\n",
        "df_train = df_joint.sample(frac=1).reset_index(drop=True)\n",
        "vectorizer.adapt(np.asarray(df_train[\"text\"]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlrQfsQ8mtmu"
      },
      "source": [
        "def build_model():\n",
        "    #init_matrix = np.load('universal.npy')\n",
        "    submodels = []\n",
        "    for kw in (3, 4, 5):    # kernel sizes\n",
        "        submodel = Sequential()\n",
        "        submodel.add(Embedding(\n",
        "        20002,\n",
        "        100,\n",
        "        embeddings_initializer=keras.initializers.Constant(np.load('embed_matrix.npy')),\n",
        "        trainable=False,))\n",
        "        submodel.add(Conv1D(100,    \n",
        "                            kw,\n",
        "                            padding='valid',\n",
        "                            activation='relu',\n",
        "                            strides=1, kernel_constraint=max_norm(5.397124926498551)\n",
        "                             ))\n",
        "        submodel.add(GlobalMaxPooling1D())\n",
        "        submodels.append(submodel)\n",
        "\n",
        "    submodel1 = submodels[0]\n",
        "    submodel2 = submodels[1]\n",
        "    submodel3 = submodels[2]\n",
        "\n",
        "    x = add([submodel1.output, submodel2.output, submodel3.output])\n",
        "    \n",
        "    big_model = Sequential()\n",
        "    big_model.add(Dropout(0.09225974322037533))\n",
        "    big_model.add(Dense(25))\n",
        "    big_model.add(Dropout(0.20942239619394942))\n",
        "    big_model.add(Activation('relu'))\n",
        "    big_model.add(Dense(1))\n",
        "    big_model.add(Activation('sigmoid'))\n",
        "\n",
        "    big_model_output = big_model(x)\n",
        "\n",
        "    model = Model([submodel1.input, submodel2.input, submodel3.input], big_model_output)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])  \n",
        "\n",
        "    print(model.summary())  \n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqnfmMEPmtmv"
      },
      "source": [
        "def train_model(df):\n",
        "    #creating the desired vectors\n",
        "    text = np.asarray(df['text'])\n",
        "    y = df[\"label\"]\n",
        "    text_train, text_test, y_train, y_test = train_test_split(\n",
        "    text, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    text_train, text_val, y_train, y_val = train_test_split(\n",
        "    text_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    X_train = vectorizer(text_train)\n",
        "    X_val = vectorizer(text_val)\n",
        "    X_test = vectorizer(text_test)\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    model.fit([X_train, X_train, X_train],\n",
        "                     y_train,\n",
        "                     batch_size=32,\n",
        "                     epochs=25,\n",
        "                     validation_data=([X_val, X_val, X_val],\n",
        "                     y_val))\n",
        "    \n",
        "    loss, accuracy =  model.evaluate([X_test, X_test, X_test], y_test)\n",
        "\n",
        "    print(\"Loss: \", loss)\n",
        "    print(\"Accuracy: \", accuracy)\n",
        "        \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCDrRwmJmtmv",
        "outputId": "b0646659-8f0c-4b10-a369-08093b97f4eb"
      },
      "source": [
        "train_model(df_medium)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "embedding_input (InputLayer)    [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1_input (InputLayer)  [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2_input (InputLayer)  [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 100)    2000200     embedding_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    2000200     embedding_1_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    2000200     embedding_2_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, None, 100)    30100       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 100)    40100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 100)    50100       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 100)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 100)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 1)            8263        add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 6,129,163\n",
            "Trainable params: 128,563\n",
            "Non-trainable params: 6,000,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 20s 225ms/step - loss: 1.0071 - accuracy: 0.5340 - val_loss: 0.6376 - val_accuracy: 0.6791\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.6030 - accuracy: 0.6724 - val_loss: 0.5010 - val_accuracy: 0.7537\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 17s 202ms/step - loss: 0.4947 - accuracy: 0.7689 - val_loss: 0.4434 - val_accuracy: 0.8075\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 17s 204ms/step - loss: 0.3857 - accuracy: 0.8332 - val_loss: 0.4418 - val_accuracy: 0.7925\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 18s 210ms/step - loss: 0.2881 - accuracy: 0.8650 - val_loss: 0.3976 - val_accuracy: 0.8194\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 18s 209ms/step - loss: 0.2107 - accuracy: 0.9263 - val_loss: 0.4218 - val_accuracy: 0.8045\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 19s 224ms/step - loss: 0.1426 - accuracy: 0.9541 - val_loss: 0.5105 - val_accuracy: 0.7985\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 19s 230ms/step - loss: 0.0972 - accuracy: 0.9666 - val_loss: 0.4703 - val_accuracy: 0.8269\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 18s 209ms/step - loss: 0.0798 - accuracy: 0.9759 - val_loss: 0.5010 - val_accuracy: 0.8164\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 18s 211ms/step - loss: 0.0477 - accuracy: 0.9880 - val_loss: 0.5366 - val_accuracy: 0.8164\n",
            "Epoch 11/25\n",
            "43/84 [==============>...............] - ETA: 9s - loss: 0.0483 - accuracy: 0.9801"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-fce9833dfcef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_medium\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-6-273a41b5af3d>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     model.fit([X_train, X_train, X_train],\n\u001b[0m\u001b[0;32m     18\u001b[0m                      \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSIAPcAvoHa7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4UIdSfSxOQv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}