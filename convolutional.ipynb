{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = pd.read_csv(\"data/processed/processed_short.csv\")\n",
    "df_medium = pd.read_csv(\"data/processed/processed_medium.csv\")\n",
    "df_dank = pd.read_csv(\"data/processed/processed_dank.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    init_matrix = pickle.load(open( \"init_matrix.p\", \"rb\" ))\n",
    "    submodels = []\n",
    "    for kw in (3, 4, 5):    # kernel sizes\n",
    "        submodel = Sequential()\n",
    "        submodel.add(Embedding(\n",
    "        30002,\n",
    "        100,\n",
    "        embeddings_initializer=keras.initializers.Constant(init_matrix),\n",
    "        trainable=False\n",
    "    ))\n",
    "        submodel.add(Conv1D(100,    #should be 100 maps\n",
    "                            kw,\n",
    "                            padding='valid',\n",
    "                            activation='relu',\n",
    "                            strides=1, kernel_constraint=max_norm(3.7))) #elvileg egy maxnorm nem árt még bele\n",
    "        submodel.add(GlobalMaxPooling1D())\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    submodel1 = submodels[0]\n",
    "    submodel2 = submodels[1]\n",
    "    submodel3 = submodels[2]\n",
    "\n",
    "    x = add([submodel1.output, submodel2.output, submodel3.output])\n",
    "    \n",
    "    big_model = Sequential()\n",
    "    big_model.add(Dropout(0.25))\n",
    "    big_model.add(Dense(50))\n",
    "    big_model.add(Dropout(0.6))\n",
    "    big_model.add(Activation('relu'))\n",
    "    big_model.add(Dense(1))\n",
    "    big_model.add(Activation('sigmoid'))\n",
    "\n",
    "    big_model_output = big_model(x)\n",
    "\n",
    "    model = Model([submodel1.input, submodel2.input, submodel3.input], big_model_output)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])  \n",
    "\n",
    "    print(model.summary())  \n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=30000, output_sequence_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    #creating the desired vectors\n",
    "    text = np.asarray(df['text'])\n",
    "    y = df[\"label\"]\n",
    "    text_train, text_test, y_train, y_test = train_test_split(\n",
    "    text, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    text_train, text_val, y_train, y_val = train_test_split(\n",
    "    text_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "    X_train = vectorizer(text_train)\n",
    "    X_val = vectorizer(text_val)\n",
    "    X_test = vectorizer(text_test)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.fit([X_train, X_train, X_train],\n",
    "                     y_train,\n",
    "                     batch_size=64,\n",
    "                     epochs=25,\n",
    "                     validation_data=([X_val, X_val, X_val],\n",
    "                     y_val))\n",
    "    \n",
    "    loss, accuracy =  model.evaluate([X_test, X_test, X_test], y_test)\n",
    "\n",
    "    print(\"Loss: \", loss)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "        \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_10_input (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11_input (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12_input (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, None, 100)    3000200     embedding_10_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, None, 100)    3000200     embedding_11_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, None, 100)    3000200     embedding_12_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 100)    30100       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 100)    40100       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 100)    50100       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 100)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 100)          0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 100)          0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100)          0           global_max_pooling1d_9[0][0]     \n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_16 (Sequential)      (None, 1)            5611        add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 9,126,511\n",
      "Trainable params: 125,911\n",
      "Non-trainable params: 9,000,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 5s 120ms/step - loss: 1.2525 - accuracy: 0.5135 - val_loss: 0.6905 - val_accuracy: 0.5606\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.7099 - accuracy: 0.4989 - val_loss: 0.6922 - val_accuracy: 0.5045\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.6923 - accuracy: 0.5248 - val_loss: 0.6896 - val_accuracy: 0.5253\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.6885 - accuracy: 0.5410 - val_loss: 0.6904 - val_accuracy: 0.6175\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.6909 - accuracy: 0.5313 - val_loss: 0.6876 - val_accuracy: 0.5335\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.6858 - accuracy: 0.5535 - val_loss: 0.6826 - val_accuracy: 0.6438\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.6798 - accuracy: 0.5626 - val_loss: 0.6795 - val_accuracy: 0.5542\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.6695 - accuracy: 0.5777 - val_loss: 0.6569 - val_accuracy: 0.6528\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.6465 - accuracy: 0.6174 - val_loss: 0.6359 - val_accuracy: 0.7080\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.6292 - accuracy: 0.6447 - val_loss: 0.5819 - val_accuracy: 0.7613\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.5976 - accuracy: 0.6532 - val_loss: 0.5548 - val_accuracy: 0.7505\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.5732 - accuracy: 0.6987 - val_loss: 0.5443 - val_accuracy: 0.7369\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.5423 - accuracy: 0.7274 - val_loss: 0.5037 - val_accuracy: 0.7821\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.4685 - val_accuracy: 0.7722\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.4203 - accuracy: 0.8171 - val_loss: 0.4419 - val_accuracy: 0.7911\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.3876 - accuracy: 0.8339 - val_loss: 0.4322 - val_accuracy: 0.7866\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.3511 - accuracy: 0.8451 - val_loss: 0.4375 - val_accuracy: 0.7939\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.3600 - accuracy: 0.8455 - val_loss: 0.4410 - val_accuracy: 0.7911\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.2717 - accuracy: 0.8894 - val_loss: 0.4436 - val_accuracy: 0.7920\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.2393 - accuracy: 0.9071 - val_loss: 0.4652 - val_accuracy: 0.7911\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 4s 125ms/step - loss: 0.1846 - accuracy: 0.9358 - val_loss: 0.4610 - val_accuracy: 0.7975\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 5s 130ms/step - loss: 0.1733 - accuracy: 0.9392 - val_loss: 0.4818 - val_accuracy: 0.7948\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.1606 - accuracy: 0.9475 - val_loss: 0.4877 - val_accuracy: 0.8038\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.1113 - accuracy: 0.9729 - val_loss: 0.5254 - val_accuracy: 0.8011\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0849 - accuracy: 0.9755 - val_loss: 0.5687 - val_accuracy: 0.7893\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5581 - accuracy: 0.7933\n",
      "Loss:  0.5581064820289612\n",
      "Accuracy:  0.7933333516120911\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x23108047370>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train_model(df_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}